# Voice Assistant - OpenClaw è¯­éŸ³åŠ©æ‰‹

å°Tè¯­éŸ³åŠ©æ‰‹ï¼Œé›†æˆ VAD â†’ STT â†’ OpenClaw â†’ TTS å®Œæ•´è¯­éŸ³å¯¹è¯æµç¨‹ã€‚

## Features

- ğŸ¤ **VADè¯­éŸ³æ£€æµ‹** - è‡ªåŠ¨æ£€æµ‹è¯´è¯å¼€å§‹/ç»“æŸ
- ğŸ—£ï¸ **STTè¯­éŸ³è¯†åˆ«** - Web Speech API ä¸­æ–‡è¯†åˆ«
- ğŸ¤– **OpenClawé›†æˆ** - å‘é€æ¶ˆæ¯åˆ°OpenClawå¤„ç†
- ğŸ”Š **TTSè¯­éŸ³åˆæˆ** - ä¸­æ–‡è¯­éŸ³å›å¤
- ğŸ¨ **3Dç•Œé¢** - å°Té£æ ¼å…¨æ¯å¤´åƒ
- ğŸ’¬ **å¯¹è¯å†å²** - å®æ—¶æ˜¾ç¤ºå¯¹è¯å†…å®¹

## Setup

### Dependencies
```bash
# æ— éœ€é¢å¤–ä¾èµ–
# ä½¿ç”¨æµè§ˆå™¨åŸç”Ÿ API
# - Web Speech API (STT + TTS)
# - Web Audio API (VAD)
# - WebRTC (å¯é€‰)
```

### Quick Start
```html
<!DOCTYPE html>
<html>
<head>
    <script src="js/xiaot-core.js"></script>
    <script src="js/vad.js"></script>
    <script src="js/assistant.js"></script>
</head>
<body>
    <div id="xiaot"></div>
    <script>
        const assistant = new XiaotVoiceAssistant({
            openclawUrl: 'http://localhost:11434',
            openclawSession: 'main',
            vadThreshold: 0.5,
            sttLanguage: 'zh-CN'
        });

        await assistant.init();
        await assistant.startListening();
    </script>
</body>
</html>
```

## Usage

### Basic Example

```javascript
// åˆ›å»ºåŠ©æ‰‹
const assistant = new XiaotVoiceAssistant({
    openclawUrl: 'http://localhost:11434',  // OpenClaw API åœ°å€
    openclawSession: 'main',                 // ä¼šè¯ID
    vadThreshold: 0.5,                       // VADé˜ˆå€¼
    sttLanguage: 'zh-CN',                    // è¯†åˆ«è¯­è¨€
    ttsVoice: 'Google æ™®é€šè¯',               // TTSè¯­éŸ³
    ttsRate: 1.0,                            // è¯­é€Ÿ
    ttsPitch: 1.0                            // éŸ³è°ƒ
});

// è®¾ç½®å›è°ƒ
assistant.onStatusChange = (state, message) => {
    console.log(`Status: ${state} - ${message}`);
};

assistant.onTranscript = (text, isFinal) => {
    if (isFinal) {
        console.log(`Recognized: ${text}`);
    }
};

assistant.onResponse = (data) => {
    console.log('Response:', data.response);
};

assistant.onSpeakingStart = () => {
    console.log('ğŸ¤ Started speaking');
};

assistant.onSpeakingEnd = () => {
    console.log('ğŸ”‡ Stopped speaking');
};

assistant.onError = (error) => {
    console.error('Error:', error);
};

// åˆå§‹åŒ–å¹¶å¼€å§‹
await assistant.init();
await assistant.startListening();

// åœæ­¢
assistant.stopListening();

// æ¸…ç†
assistant.dispose();
```

### Advanced: Manual Control

```javascript
// æ‰‹åŠ¨è§¦å‘TTS
await assistant.speak('ä½ å¥½ï¼Œæˆ‘æ˜¯å°Tï¼');

// æ‰“æ–­è¯´è¯
assistant.interrupt();

// è·å–çŠ¶æ€
console.log(assistant.isListening);   // æ˜¯å¦åœ¨ç›‘å¬
console.log(assistant.isSpeaking);    // æ˜¯å¦åœ¨è¯´è¯
console.log(assistant.isProcessing);  // æ˜¯å¦åœ¨å¤„ç†
```

### With Custom VAD

```javascript
// è‡ªå®šä¹‰VADé…ç½®
const assistant = new XiaotVoiceAssistant({
    vadThreshold: 0.6,              // æé«˜é˜ˆå€¼å‡å°‘è¯¯æ£€
    vadSilenceDuration: 1.0,        // å»¶é•¿é™éŸ³æ—¶é—´
    autoListen: true                // è‡ªåŠ¨å¼€å§‹ç›‘å¬
});
```

## API Reference

### Constructor Options

```javascript
{
    openclawUrl: 'http://localhost:11434',  // OpenClaw API åœ°å€
    openclawSession: 'main',                 // ä¼šè¯ID
    vadThreshold: 0.5,                       // VADæ£€æµ‹é˜ˆå€¼ (0-1)
    vadSilenceDuration: 0.8,                 // åœæ­¢è¯´è¯çš„é™éŸ³æ—¶é•¿(ç§’)
    sttLanguage: 'zh-CN',                    // è¯­éŸ³è¯†åˆ«è¯­è¨€
    ttsVoice: 'Google æ™®é€šè¯',               // TTSè¯­éŸ³åç§°
    ttsRate: 1.0,                            // TTSè¯­é€Ÿ (0.5-2)
    ttsPitch: 1.0,                           // TTSéŸ³è°ƒ (0.5-2)
    autoListen: true                         // åˆå§‹åŒ–åè‡ªåŠ¨å¼€å§‹ç›‘å¬
}
```

### Methods

| Method | Description |
|--------|-------------|
| `await init()` | åˆå§‹åŒ–VADã€STTã€TTS |
| `await startListening()` | å¼€å§‹ç›‘å¬éº¦å…‹é£ |
| `stopListening()` | åœæ­¢ç›‘å¬ |
| `await speak(text)` | è¯­éŸ³åˆæˆå¹¶æ’­æ”¾ |
| `interrupt()` | æ‰“æ–­å½“å‰è¯­éŸ³ |
| `dispose()` | æ¸…ç†èµ„æº |

### Properties

| Property | Type | Description |
|----------|------|-------------|
| `isListening` | boolean | æ˜¯å¦æ­£åœ¨ç›‘å¬ |
| `isSpeaking` | boolean | æ˜¯å¦æ­£åœ¨æ’­æ”¾è¯­éŸ³ |
| `isProcessing` | boolean | æ˜¯å¦æ­£åœ¨å¤„ç† |
| `conversationHistory` | array | å¯¹è¯å†å² |

### Callbacks

| Callback | Parameters | Description |
|----------|------------|-------------|
| `onStatusChange` | `(state, message)` | çŠ¶æ€å˜åŒ– |
| `onTranscript` | `(text, isFinal)` | è¯­éŸ³è¯†åˆ«ç»“æœ |
| `onResponse` | `{response, ...}` | OpenClawå›å¤ |
| `onSpeakingStart` | `()` | å¼€å§‹æ’­æ”¾è¯­éŸ³ |
| `onSpeakingEnd` | `()` | æ’­æ”¾å®Œæˆ |
| `onError` | `(error)` | å‘ç”Ÿé”™è¯¯ |

## Demo

Open `index.html` for a complete interactive demo:

```bash
cd voice-assistant
python3 -m http.server 8080
# Visit http://localhost:8080/index.html
```

### Demo Features:
- ğŸ¤ Click to start/stop voice conversation
- ğŸ“Š VAD visualization (probability meter)
- ğŸ’¬ Real-time chat history
- ğŸ¨ 3D å°Té£æ ¼ avatar
- ğŸ”§ OpenClaw connection config
- ğŸ”Š TTS test button

## OpenClaw Integration

### Send Message to OpenClaw

```javascript
// é€šè¿‡APIå‘é€æ¶ˆæ¯
POST http://localhost:11434/api/sessions/{session}/messages
{
    "message": "ä½ çš„è¯­éŸ³è¯†åˆ«ç»“æœ"
}

// å“åº”
{
    "response": "OpenClawçš„å›å¤æ–‡æœ¬"
}
```

### WebSocketå®æ—¶é€šä¿¡ (å¯é€‰)

```javascript
// è¿æ¥åˆ°OpenClaw WebSocket
const ws = new WebSocket('ws://localhost:11434/ws');

// å‘é€è¯­éŸ³
ws.send(JSON.stringify({
    type: 'voice_input',
    text: recognizedText
}));

// æ¥æ”¶å›å¤
ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    if (data.type === 'response') {
        assistant.speak(data.text);
    }
};
```

## Troubleshooting

### "SpeechRecognition not found"
- Chrome/Edge: é»˜è®¤æ”¯æŒ
- Safari: éœ€è¦ç”¨æˆ·æ‰‹åŠ¨å¯ç”¨
- Firefox: éœ€è¦é…ç½®

### Microphone permission denied
- æ£€æŸ¥æµè§ˆå™¨åœ°å€æ å·¦ä¾§çš„æƒé™å›¾æ ‡
- ç¡®è®¤ä¸ºHTTPSæˆ–localhost
- ç³»ç»Ÿè®¾ç½® > éšç§ > éº¦å…‹é£ > å…è®¸æµè§ˆå™¨

### TTS voice not found
```javascript
// æŸ¥çœ‹å¯ç”¨è¯­éŸ³
console.log(assistant.ttsVoices);

// æ‰‹åŠ¨é€‰æ‹©
const voice = assistant.ttsVoices.find(v => v.lang.includes('zh'));
```

### VAD too sensitive / not sensitive
```javascript
// è°ƒæ•´é˜ˆå€¼
const assistant = new XiaotVoiceAssistant({
    vadThreshold: 0.3,  // é™ä½: æ›´æ•æ„Ÿ
    // æˆ–
    vadThreshold: 0.7   // æé«˜: æ›´ä¸¥æ ¼
});
```

## Files

```
voice-assistant/
â”œâ”€â”€ SKILL.md            # This file
â”œâ”€â”€ index.html          # ğŸ® Interactive demo
â””â”€â”€ js/
    â”œâ”€â”€ assistant.js    # Core assistant
    â”œâ”€â”€ xiaot-core.js   # 3D avatar
    â””â”€â”€ vad.js          # Voice activity detection
```

## Browser Support

| Browser | STT | TTS | Web Audio |
|---------|-----|-----|-----------|
| Chrome | âœ… | âœ… | âœ… |
| Edge | âœ… | âœ… | âœ… |
| Safari | âš ï¸ | âœ… | âœ… |
| Firefox | âš ï¸ | âœ… | âœ… |

âš ï¸ STTå¯èƒ½éœ€è¦æ‰‹åŠ¨å¯ç”¨

## License

MIT
